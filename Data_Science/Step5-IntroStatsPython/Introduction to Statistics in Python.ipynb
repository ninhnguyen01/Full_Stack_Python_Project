{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c697f6",
   "metadata": {},
   "source": [
    "# Introduction to Statistics in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0063e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e23d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_consumption = pd.read_csv('data/food_consumption.csv')\n",
    "food_consumption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_consumption.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15697c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Belgium\n",
    "be_consumption = food_consumption[food_consumption['country'] == 'Belgium']\n",
    "\n",
    "# Filter for USA\n",
    "usa_consumption = food_consumption[food_consumption['country'] == 'USA']\n",
    "\n",
    "# Calculate mean and median consumption in Belgium\n",
    "print(np.mean(be_consumption['consumption']))\n",
    "print(np.median(be_consumption['consumption']))\n",
    "\n",
    "# Calculate mean and median consumption in USA\n",
    "print(np.mean(usa_consumption['consumption']))\n",
    "print(np.median(usa_consumption['consumption']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f249b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for Belgium and USA only\n",
    "be_and_usa = food_consumption[(food_consumption['country'] == \"Belgium\") | (food_consumption['country'] == 'USA')]\n",
    "\n",
    "# Group by country, select consumption column, and compute mean and median\n",
    "be_and_usa.groupby('country')['consumption'].agg([np.mean, np.median])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76532767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d59bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for food_category equals rice\n",
    "rice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\n",
    "\n",
    "# Histogram of co2_emission for rice and show plot\n",
    "rice_consumption['co2_emission'].hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset for food_category equals rice\n",
    "rice_consumption = food_consumption[food_consumption['food_category'] == 'rice']\n",
    "\n",
    "# Calculate mean and median of co2_emission with .agg()\n",
    "rice_consumption['co2_emission'].agg([np.mean, np.median])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44942f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the quartiles of co2_emission\n",
    "print(np.quantile(food_consumption['co2_emission'], [0, 0.25, 0.5, 0.75, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the quintiles of co2_emission\n",
    "print(np.quantile(food_consumption['co2_emission'], [0, 0.2, 0.4, 0.6, 0.8, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d81679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the deciles of co2_emission\n",
    "print(np.quantile(food_consumption['co2_emission'], np.linspace(0, 1, 11)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f78a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print variance and sd of co2_emission for each food_category\n",
    "food_consumption.groupby('food_category')['co2_emission'].agg([np.var, np.std])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'beef'\n",
    "food_consumption[food_consumption['food_category'] == 'beef']['co2_emission'].hist()\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Create histogram of co2_emission for food_category 'eggs'\n",
    "food_consumption[food_consumption['food_category'] == 'eggs']['co2_emission'].hist()\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30beca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total co2_emission per country: emissions_by_country\n",
    "emissions_by_country = food_consumption.groupby('country')['co2_emission'].sum()\n",
    "emissions_by_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a74443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the first and third quartiles and IQR of emissions_by_country\n",
    "q1 = np.quantile(emissions_by_country, 0.25)\n",
    "q3 = np.quantile(emissions_by_country, 0.75)\n",
    "iqr = q3 - q1\n",
    "iqr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cec827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the lower and upper cutoffs for outliers\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "print(lower)\n",
    "print(upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset emissions_by_country to find outliers\n",
    "outliers = emissions_by_country[(emissions_by_country < lower) | (emissions_by_country > upper)]\n",
    "outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "amir_deals = pd.read_csv('data/amir_deals.csv')\n",
    "amir_deals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "amir_deals = amir_deals.drop(columns=['Unnamed: 0'])\n",
    "amir_deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04bb170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the deals for each product\n",
    "counts = amir_deals['product'].value_counts()\n",
    "counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of picking a deal with each product\n",
    "probs = counts / amir_deals.shape[0]\n",
    "probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(24)\n",
    "\n",
    "# Sample 5 deals without replacement\n",
    "sample_without_replacement = amir_deals.sample(5)\n",
    "sample_without_replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(24)\n",
    "\n",
    "# Sample 5 deals with replacement\n",
    "sample_with_replacement = amir_deals.sample(5, replace=True)\n",
    "sample_with_replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_consumption['co2_emission'].hist(bins=np.linspace(2,6,5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbb95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create probability distribution\n",
    "size_dist = food_consumption['co2_emission'].value_counts() / food_consumption.shape[0]\n",
    "\n",
    "# Reset index and rename columns\n",
    "size_dist = size_dist.reset_index()\n",
    "size_dist.columns = ['co2_emission', 'prob']\n",
    "\n",
    "size_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34269b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected value\n",
    "expected_value = np.sum(size_dist['co2_emission'] * size_dist['prob'])\n",
    "expected_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f54b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset groups of size 4 or more\n",
    "groups_4_or_more = size_dist[size_dist['co2_emission'] >= 4]\n",
    "\n",
    "# Sum the probabilities of groups_4_or_more\n",
    "prob_4_or_more = np.sum(groups_4_or_more['co2_emission'])\n",
    "prob_4_or_more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050eace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min and max wait times for back-up that happens every 30 min\n",
    "min_time = 0\n",
    "max_time = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83407f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import uniform from scipy.stats\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Calculate probability of waiting less than 5 mins\n",
    "prob_less_than_5 = uniform.cdf(5, min_time, max_time)\n",
    "prob_less_than_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of waiting more than 5 mins\n",
    "prob_greater_than_5 = 1 - uniform.cdf(5, min_time, max_time)\n",
    "prob_greater_than_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability of waiting 10-20 mins\n",
    "prob_between_10_and_20 = uniform.cdf(20, min_time, max_time) - uniform.cdf(10, min_time, max_time)\n",
    "prob_between_10_and_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdeed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to 334\n",
    "np.random.seed(334)\n",
    "\n",
    "# Import uniform\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Generate 1000 wait times between 0 and 30 mins\n",
    "wait_times = uniform.rvs(0, 30, size=1000)\n",
    "\n",
    "# Create a histogram of simulated times and show plot\n",
    "plt.hist(wait_times)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd8733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import binom from scipy.stats\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Set random seed to 10\n",
    "np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a single deal\n",
    "print(binom.rvs(1, 0.3, size=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf621a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 1 week of 3 deals\n",
    "print(binom.rvs(3, 0.3, size=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7669330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 52 weeks of 3 deals\n",
    "deals = binom.rvs(3, 0.3, size=52)\n",
    "\n",
    "# Print mean deals won per week\n",
    "print(np.mean(deals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7305813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of closing 3 out of 3 deals\n",
    "prob_3 = binom.pmf(3, 3, 0.3)\n",
    "\n",
    "print(prob_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476daae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of closing <= 1 deal out of 3 deals\n",
    "prob_less_than_or_equal_1 = binom.cdf(1, 3, 0.3)\n",
    "\n",
    "print(prob_less_than_or_equal_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffb948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of closing > 1 deal out of 3 deals\n",
    "prob_greater_than_1 = 1 - binom.cdf(1, 3, 0.3)\n",
    "\n",
    "print(prob_greater_than_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45879ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected number won with 30% win rate\n",
    "won_30pct = 3 * 0.3\n",
    "print(won_30pct)\n",
    "\n",
    "# Expected number won with 25% win rate\n",
    "won_25pct = 3 * 0.25\n",
    "print(won_25pct)\n",
    "\n",
    "# Expected number won with 35% win rate\n",
    "won_35pct = 3 * 0.35\n",
    "print(won_35pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052fc77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of amount with 10 bins and show plot\n",
    "amir_deals['amount'].hist(bins=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d93db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of deal < 7500\n",
    "prob_less_7500 = norm.cdf(7500, 5000, 2000)\n",
    "\n",
    "print(prob_less_7500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of deal > 1000\n",
    "prob_over_1000 = 1 - norm.cdf(1000, 5000, 2000)\n",
    "\n",
    "print(prob_over_1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of deal between 3000 and 7000\n",
    "prob_3000_to_7000 = norm.cdf(7000, 5000, 2000) - norm.cdf(3000, 5000, 2000)\n",
    "\n",
    "print(prob_3000_to_7000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate amount that 25% of deals will be less than\n",
    "pct_25 = norm.ppf(0.25, 5000, 2000)\n",
    "\n",
    "print(pct_25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726eb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new average amount\n",
    "new_mean = 5000 * 1.2\n",
    "\n",
    "# Calculate new standard deviation\n",
    "new_sd = 2000 * 1.3\n",
    "\n",
    "# Simulate 36 new sales\n",
    "new_sales = norm.rvs(new_mean, new_sd, size=36)\n",
    "\n",
    "# Create histogram and show\n",
    "plt.hist(new_sales)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of num_users and show\n",
    "amir_deals['num_users'].hist()\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408ac2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed to 104\n",
    "np.random.seed(104)\n",
    "\n",
    "# Sample 20 num_users with replacement from amir_deals\n",
    "samp_20 = amir_deals['num_users'].sample(20, replace=True)\n",
    "\n",
    "# Take mean of samp_20\n",
    "print(np.mean(samp_20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e008622",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means = []\n",
    "# Loop 100 times\n",
    "for i in range(100):\n",
    "  # Take sample of 20 num_users\n",
    "  samp_20 = amir_deals['num_users'].sample(20, replace=True)\n",
    "  # Calculate mean of samp_20\n",
    "  samp_20_mean = np.mean(samp_20)\n",
    "  # Append samp_20_mean to sample_means\n",
    "  sample_means.append(samp_20_mean)\n",
    "  \n",
    "print(sample_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Series and plot histogram\n",
    "sample_means_series = pd.Series(sample_means)\n",
    "sample_means_series.hist()\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9352add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import poisson from scipy.stats\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# Probability of 5 responses\n",
    "prob_5 = poisson.pmf(5, 4)\n",
    "\n",
    "prob_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of 5 responses\n",
    "prob_coworker = poisson.pmf(5, 5.5)\n",
    "\n",
    "prob_coworker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of 2 or fewer responses\n",
    "prob_2_or_less = poisson.cdf(2, 4)\n",
    "\n",
    "print(prob_2_or_less)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da52ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of > 10 responses\n",
    "prob_over_10 = 1 - poisson.cdf(10, 4)\n",
    "\n",
    "prob_over_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import expon from scipy.stats\n",
    "from scipy.stats import expon\n",
    "\n",
    "# Print probability response takes < 1 hour\n",
    "print(expon.cdf(1, scale=2.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print probability response takes > 4 hours\n",
    "print(1 - expon.cdf(4, scale=2.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fb51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print probability response takes 3-4 hours\n",
    "print(expon.cdf(4, scale=2.5) - expon.cdf(3, scale=2.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc16c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_happiness = pd.read_csv('data/world_happiness.csv')\n",
    "world_happiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_happiness = world_happiness.drop(columns=['Unnamed: 0'])\n",
    "world_happiness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93be6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a scatterplot of happiness_score vs. life_exp and show\n",
    "sns.scatterplot(x='life_exp', y='happiness_score', data=world_happiness)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6dc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatterplot of happiness_score vs life_exp with trendline\n",
    "sns.lmplot(x='life_exp', y='happiness_score', data=world_happiness, ci=None)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45287f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatterplot of happiness_score vs life_exp with trendline\n",
    "sns.lmplot(x='life_exp', y='happiness_score', data=world_happiness, ci=None)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Correlation between life_exp and happiness_score\n",
    "cor = world_happiness['life_exp'].corr(world_happiness['happiness_score'])\n",
    "\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of gdp_per_cap and life_exp\n",
    "sns.scatterplot(x='gdp_per_cap', y='life_exp', data=world_happiness)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of gdp_per_cap and life_exp\n",
    "sns.scatterplot(x='gdp_per_cap', y='life_exp', data=world_happiness)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "  \n",
    "# Correlation between gdp_per_cap and life_exp\n",
    "cor = world_happiness['gdp_per_cap'].corr(world_happiness['life_exp'])\n",
    "\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7255f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of happiness_score vs. gdp_per_cap\n",
    "sns.scatterplot(x='gdp_per_cap', y='happiness_score', data=world_happiness)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "cor = world_happiness['gdp_per_cap'].corr(world_happiness['happiness_score'])\n",
    "cor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11756425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create log_gdp_per_cap column\n",
    "world_happiness['log_gdp_per_cap'] = np.log(world_happiness['gdp_per_cap'])\n",
    "\n",
    "# Scatterplot of happiness_score vs. log_gdp_per_cap\n",
    "sns.scatterplot(x='log_gdp_per_cap', y='happiness_score', data=world_happiness)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "cor = world_happiness['log_gdp_per_cap'].corr(world_happiness['happiness_score'])\n",
    "cor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
